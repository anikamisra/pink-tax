{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Silicone Grip Lifting Straps</td>\n",
       "      <td>$16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vital Seamless 2.0 Leggings</td>\n",
       "      <td>$54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Crew Socks 3pk</td>\n",
       "      <td>$16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Crew Socks 5pk</td>\n",
       "      <td>$26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Strong Girl Lifting Club Oversized Graphic Crew</td>\n",
       "      <td>$42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Product Price\n",
       "0           1                     Silicone Grip Lifting Straps   $16\n",
       "1           2                      Vital Seamless 2.0 Leggings   $54\n",
       "2           3                                   Crew Socks 3pk   $16\n",
       "3           4                                   Crew Socks 5pk   $26\n",
       "4           5  Strong Girl Lifting Club Oversized Graphic Crew   $42"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in data \n",
    "womens_df = pd.read_csv('/Users/anikamisra/Desktop/personal-projects/pink-tax/gymshark/w_df_scraped_jul_14.csv')\n",
    "mens_df = pd.read_csv('/Users/anikamisra/Desktop/personal-projects/pink-tax/gymshark/m_df_scraped_jul_14.csv')\n",
    "womens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of womens products:  960 \n",
      "Number of mens products:  960\n"
     ]
    }
   ],
   "source": [
    "womens_df = womens_df.drop(columns = [\"Unnamed: 0\"])\n",
    "mens_df = mens_df.drop(columns = [\"Unnamed: 0\"])\n",
    "print(\"Number of womens products: \", womens_df.shape[0], \"\\nNumber of mens products: \", mens_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the website, there are over 960 products for both mens and womens clothing. However, when I try to webscrape on a page number greater than 16 it tells me that the page does not exist, and when I try to manually load all the products it stops at page 3. So for now, we can only gain access to 960 of the products for both mens and womens products. \n",
    "\n",
    "However, this is good because there is no class imbalance. \n",
    "\n",
    "## Part 1: Create feature matrix \n",
    "BoW technique \n",
    "1. Each row is associated with a unique product description\n",
    "2. Each column represents a potential word in the vocabulary \n",
    "3. If the product description contains a certain word, put 1 in that column (or >1 if it appears more than once). Otherwise, put 0. \n",
    "4. For all women's products, put 1 in the \"womens\" column. For all men's products, put 0 in the \"mens\" column. \n",
    "\n",
    "# finish these descrptions tomorrow babe! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flex', 'zip', 'sleek', 'peek', 'elevate', 'strappy', 'v', 'contour', 'jersey', 'glute', 'heritage', 'seamless', 'out', 'gs', 'boxer', 'leggings', 'joggers', 'tracktop', 'heart', 'fit)', '2.0', 'tank', 'cover', 'stringer', 'shorts', 'everyday', 'rest', 'muscle', 'silicone', 'gym', 'ruched', 'adapt', 'graphic', 'boo', 'high', 'crest', 'marl', 'small', 'regular', 'top', '5pk', 'fit', 'lifting', 'arm', 'sport', 'legacy', 'washed', 'american', 'club', 'extreme', 'strength', 'pump', 'minimal', 'react', 't-shirt', 'waisted', 'vital', 'long', 'pocket', 'cap', 'crop', 'sports', 'training', 'socks', 'hoodie', 'lightweight', 'studio', 'strong', 'cycling', 'day', 'sharkhead', 'a', '(reg', 'crew', 'cut', 'drop', 'bra', 'essential', 'bag', 'backpack', 'power', 'neck', 'boost', 'grip', 'arrival', 'brief', 'bandeau', 'cargo', '3pk', '5\"', 'oversized', 'straps', 'fleck', 'girl', 'mesh', 'department', '7\"', 'woven', 'sleeve', 'fleece'}\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "## create list of words \n",
    "words_womens = womens_df['Product'].str.split()\n",
    "words_mens = mens_df['Product'].str.split()\n",
    "unique_words = set()\n",
    "for item in words_womens: \n",
    "    for word in item: \n",
    "        unique_words.add(word.lower())\n",
    "for item in words_mens: \n",
    "    for word in item: \n",
    "        unique_words.add(word.lower())\n",
    "print(unique_words)\n",
    "print(len(unique_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# remove nouns\n",
    "import spacy  \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "no_nouns = []\n",
    "for word in list(unique_words): \n",
    "    doc = nlp(word)\n",
    "    is_noun = False\n",
    "    for token in doc: \n",
    "        if token.pos_ == \"NOUN\": \n",
    "            is_noun = True \n",
    "            break \n",
    "    if is_noun == False: \n",
    "        no_nouns.append(word)\n",
    "\n",
    "print(len(no_nouns))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flex</th>\n",
       "      <th>zip</th>\n",
       "      <th>sleek</th>\n",
       "      <th>peek</th>\n",
       "      <th>elevate</th>\n",
       "      <th>strappy</th>\n",
       "      <th>v</th>\n",
       "      <th>contour</th>\n",
       "      <th>jersey</th>\n",
       "      <th>glute</th>\n",
       "      <th>...</th>\n",
       "      <th>3pk</th>\n",
       "      <th>5\"</th>\n",
       "      <th>oversized</th>\n",
       "      <th>fleck</th>\n",
       "      <th>7\"</th>\n",
       "      <th>woven</th>\n",
       "      <th>sleeve</th>\n",
       "      <th>fleece</th>\n",
       "      <th>womens</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      flex  zip  sleek  peek  elevate  strappy  v  contour  jersey  glute  \\\n",
       "1915     0    0      0     0        0        0  0        0       0      0   \n",
       "1916     0    0      0     0        0        0  0        0       0      0   \n",
       "1917     0    0      0     0        0        0  0        0       0      0   \n",
       "1918     0    0      0     0        0        0  0        0       0      0   \n",
       "1919     0    0      0     0        0        0  0        0       0      0   \n",
       "\n",
       "      ...  3pk  5\"  oversized  fleck  7\"  woven  sleeve  fleece  womens  Price  \n",
       "1915  ...    0   0          0      0   0      0       0       0       0   36.0  \n",
       "1916  ...    0   0          0      0   1      0       0       0       0   26.0  \n",
       "1917  ...    0   0          0      0   0      0       0       0       7   16.0  \n",
       "1918  ...    0   0          0      0   0      0       0       0       7   40.0  \n",
       "1919  ...    0   0          0      0   0      0       0       0       0   24.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create feature matrix \n",
    "\n",
    "feat_mat = pd.DataFrame(columns=no_nouns)\n",
    "feat_mat['womens'] = 0\n",
    "feat_mat['Price'] = 0\n",
    "\n",
    "# mens_df['Price'] = mens_df['Price'].str.replace('$', '')\n",
    "\n",
    "for index, row in womens_df.iterrows(): \n",
    "    product = row['Product']\n",
    "    price = row['Price']\n",
    "    \n",
    "    # initialize all column values to 0 \n",
    "    newrow = {word: 0 for word in no_nouns}\n",
    "    newrow['Price'] = float(price.replace(\"$\", \"\"))\n",
    "\n",
    "    words = set(product.lower().split())\n",
    "    for word in words: \n",
    "        if word in newrow: \n",
    "            newrow[word] = 1 \n",
    "    # since we are pulling from womens df add 1 to the \"womens\" word \n",
    "    newrow['womens'] = 7\n",
    "\n",
    "    feat_mat.loc[index] = newrow\n",
    "\n",
    "NEW_INDEX = feat_mat.shape[0] # now we append mens products from the bottom of previously created dataframe \n",
    "for index, row in mens_df.iterrows(): \n",
    "    product = row['Product']\n",
    "    price = row['Price']\n",
    "    \n",
    "    # initialize all column values to 0 \n",
    "    newrow = {word: 0 for word in no_nouns}\n",
    "    newrow['Price'] = float(price.replace(\"$\", \"\"))\n",
    "\n",
    "    words = set(product.lower().split())\n",
    "    for word in words: \n",
    "        if word in newrow: \n",
    "            newrow[word] = 1 \n",
    "    newrow['womens'] = 0\n",
    "    feat_mat.loc[index+NEW_INDEX] = newrow\n",
    "\n",
    "# shuffle rows for randomness \n",
    "feat_mat = feat_mat.sample(frac=1).reset_index(drop=True)\n",
    "feat_mat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Womens median price:  30.0 \n",
      "Mens median price:  26.3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = feat_mat\n",
    "w_df_all_data = df[df['womens'] == 7]\n",
    "m_df_all_data = df[df['womens'] == 0]\n",
    "print(\"Womens median price: \", w_df_all_data.describe().loc['50%', 'Price'],\n",
    " \"\\nMens median price: \", m_df_all_data.describe().loc['50%', 'Price'])\n",
    "\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split \n",
    "from sklearn.model_selection import train_test_split\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "x_train.to_csv(\"x_train.csv\", index=False)\n",
    "x_test.to_csv(\"x_test.csv\", index=False)\n",
    "y_train.to_csv(\"y_train.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n",
    "# save these files as csv so that we use the same data for all different types of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X train shape:  (1440, 59) \n",
      " Y train shape:  (1440, 1) \n",
      " X test shape:  (480, 59) \n",
      " Y test shape:  (480, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"x_train.csv\")\n",
    "x_test = pd.read_csv(\"x_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    "print(\" X train shape: \", x_train.shape, \n",
    "      \"\\n Y train shape: \", y_train.shape,\n",
    "       \"\\n X test shape: \", x_test.shape, \n",
    "         \"\\n Y test shape: \", y_test.shape)\n",
    "\n",
    "y_test = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  33.146373482112296\n",
      "Correlation:  0.8357839275061998\n"
     ]
    }
   ],
   "source": [
    "# lasso (linear pricing model)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred = lasso.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(\"Correlation: \", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Coefficient\n",
      "58  womens      0.08726\n"
     ]
    }
   ],
   "source": [
    "coefs = lasso.coef_\n",
    "feature_names = x_train.columns\n",
    "coefs_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "womens_coef = coefs_df[coefs_df['Feature'].str.contains('womens', case=False, na=False)]\n",
    "print(womens_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So according to a linear pricing model, the womens label is not influential at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.9160473036947532\n",
      "Mean squared error:  13.938015439933672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/btr2krsx7hx6jcjm7m5dn87m0000gn/T/ipykernel_10266/2580542958.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfr.fit(x_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "# random forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(random_state=16)\n",
    "rfr.fit(x_train, y_train)\n",
    "y_pred = rfr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(\"Pearson correlation coefficient:\", corr)\n",
    "print(\"Mean squared error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np \n",
    "\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "explainer = shap.Explainer(rfr)\n",
    "\n",
    "shap_values = explainer.shap_values(x_train, check_additivity=False)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# save SHAP values to a file\n",
    "with open('shap_values.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Mean SHAP Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>womens</td>\n",
       "      <td>-0.283924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>oversized</td>\n",
       "      <td>-0.100318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gs</td>\n",
       "      <td>-0.092023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hoodie</td>\n",
       "      <td>-0.059680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3pk</td>\n",
       "      <td>-0.043141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Mean SHAP Value\n",
       "58     womens        -0.283924\n",
       "52  oversized        -0.100318\n",
       "12         gs        -0.092023\n",
       "42     hoodie        -0.059680\n",
       "50        3pk        -0.043141"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS WHEN U WANT TO LOAD UP SHAP VALUES AGAIN \n",
    "import pickle\n",
    "with open('shap_values.pkl', 'rb') as f:\n",
    "    shap_values = pickle.load(f)\n",
    "\n",
    "shap_values = shap.Explanation(values=shap_values, base_values=explainer.expected_value, data=x_train, feature_names=x_train.columns)\n",
    "mean_shap_values = pd.DataFrame({\n",
    "    'Feature': x_train.columns, \n",
    "    'Mean SHAP Value': np.mean(shap_values.values, axis=0)\n",
    "})\n",
    "\n",
    "mean_shap_values = mean_shap_values.sort_values(by='Mean SHAP Value', ascending=True)\n",
    "mean_shap_values.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
