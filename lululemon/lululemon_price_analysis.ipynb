{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyhole</th>\n",
       "      <th>10\"</th>\n",
       "      <th>wool-knit</th>\n",
       "      <th>cpc</th>\n",
       "      <th>side-snap</th>\n",
       "      <th>rest</th>\n",
       "      <th>hiking</th>\n",
       "      <th>unisex</th>\n",
       "      <th>v</th>\n",
       "      <th>button-up</th>\n",
       "      <th>...</th>\n",
       "      <th>this</th>\n",
       "      <th>cord</th>\n",
       "      <th>train</th>\n",
       "      <th>tapered</th>\n",
       "      <th>textured</th>\n",
       "      <th>a-d</th>\n",
       "      <th>super-high-rise</th>\n",
       "      <th>nulux</th>\n",
       "      <th>ruched</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyhole  10\"  wool-knit  cpc  side-snap  rest  hiking  unisex  v  \\\n",
       "0        0    0          0    0          0     0       0       0  0   \n",
       "1        0    0          0    0          0     0       0       0  0   \n",
       "2        0    0          0    0          0     0       0       0  0   \n",
       "3        0    0          0    0          0     0       0       0  0   \n",
       "4        0    0          0    0          0     0       0       0  0   \n",
       "\n",
       "   button-up  ...  this  cord  train  tapered  textured  a-d  super-high-rise  \\\n",
       "0          0  ...     0     0      0        0         0    0                0   \n",
       "1          0  ...     0     0      0        0         0    0                0   \n",
       "2          0  ...     0     0      0        0         0    0                0   \n",
       "3          0  ...     0     0      0        0         0    0                0   \n",
       "4          0  ...     0     0      0        0         0    0                0   \n",
       "\n",
       "   nulux  ruched  Price  \n",
       "0      0       0  118.0  \n",
       "1      0       0  128.0  \n",
       "2      0       0   78.0  \n",
       "3      0       0   78.0  \n",
       "4      0       0  118.0  \n",
       "\n",
       "[5 rows x 708 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"lululemon_feature_matrix.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 708) (537, 708)\n"
     ]
    }
   ],
   "source": [
    "w_df_all_data = df[df['womens'] == 1]\n",
    "m_df_all_data = df[df['womens'] == 0]\n",
    "\n",
    "print(w_df_all_data.shape, m_df_all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyhole</th>\n",
       "      <th>10\"</th>\n",
       "      <th>wool-knit</th>\n",
       "      <th>cpc</th>\n",
       "      <th>side-snap</th>\n",
       "      <th>rest</th>\n",
       "      <th>hiking</th>\n",
       "      <th>unisex</th>\n",
       "      <th>v</th>\n",
       "      <th>button-up</th>\n",
       "      <th>...</th>\n",
       "      <th>this</th>\n",
       "      <th>cord</th>\n",
       "      <th>train</th>\n",
       "      <th>tapered</th>\n",
       "      <th>textured</th>\n",
       "      <th>a-d</th>\n",
       "      <th>super-high-rise</th>\n",
       "      <th>nulux</th>\n",
       "      <th>ruched</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.0</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.0</td>\n",
       "      <td>...</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>846.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>77.794917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076695</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.096840</td>\n",
       "      <td>0.068639</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096840</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.260760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.113351</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>43.278870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyhole         10\"  wool-knit         cpc   side-snap        rest  \\\n",
       "count  846.000000  846.000000      846.0  846.000000  846.000000  846.000000   \n",
       "mean     0.002364    0.001182        0.0    0.005910    0.001182    0.001182   \n",
       "std      0.048593    0.034381        0.0    0.076695    0.034381    0.034381   \n",
       "min      0.000000    0.000000        0.0    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000        0.0    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000        0.0    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000        0.0    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000        0.0    1.000000    1.000000    1.000000   \n",
       "\n",
       "           hiking      unisex           v  button-up  ...        this  \\\n",
       "count  846.000000  846.000000  846.000000      846.0  ...  846.000000   \n",
       "mean     0.009456    0.004728    0.002364        0.0  ...    0.009456   \n",
       "std      0.096840    0.068639    0.048593        0.0  ...    0.096840   \n",
       "min      0.000000    0.000000    0.000000        0.0  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000        0.0  ...    0.000000   \n",
       "50%      0.000000    0.000000    0.000000        0.0  ...    0.000000   \n",
       "75%      0.000000    0.000000    0.000000        0.0  ...    0.000000   \n",
       "max      1.000000    1.000000    1.000000        0.0  ...    1.000000   \n",
       "\n",
       "             cord       train  tapered  textured         a-d  super-high-rise  \\\n",
       "count  846.000000  846.000000    846.0     846.0  846.000000       846.000000   \n",
       "mean     0.002364    0.073286      0.0       0.0    0.002364         0.013002   \n",
       "std      0.048593    0.260760      0.0       0.0    0.048593         0.113351   \n",
       "min      0.000000    0.000000      0.0       0.0    0.000000         0.000000   \n",
       "25%      0.000000    0.000000      0.0       0.0    0.000000         0.000000   \n",
       "50%      0.000000    0.000000      0.0       0.0    0.000000         0.000000   \n",
       "75%      0.000000    0.000000      0.0       0.0    0.000000         0.000000   \n",
       "max      1.000000    1.000000      0.0       0.0    1.000000         1.000000   \n",
       "\n",
       "            nulux      ruched       Price  \n",
       "count  846.000000  846.000000  846.000000  \n",
       "mean     0.001182    0.002364   77.794917  \n",
       "std      0.034381    0.048593   43.278870  \n",
       "min      0.000000    0.000000    9.000000  \n",
       "25%      0.000000    0.000000   48.000000  \n",
       "50%      0.000000    0.000000   68.000000  \n",
       "75%      0.000000    0.000000   99.000000  \n",
       "max      1.000000    1.000000  398.000000  \n",
       "\n",
       "[8 rows x 708 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_df_all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyhole</th>\n",
       "      <th>10\"</th>\n",
       "      <th>wool-knit</th>\n",
       "      <th>cpc</th>\n",
       "      <th>side-snap</th>\n",
       "      <th>rest</th>\n",
       "      <th>hiking</th>\n",
       "      <th>unisex</th>\n",
       "      <th>v</th>\n",
       "      <th>button-up</th>\n",
       "      <th>...</th>\n",
       "      <th>this</th>\n",
       "      <th>cord</th>\n",
       "      <th>train</th>\n",
       "      <th>tapered</th>\n",
       "      <th>textured</th>\n",
       "      <th>a-d</th>\n",
       "      <th>super-high-rise</th>\n",
       "      <th>nulux</th>\n",
       "      <th>ruched</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>537.0</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.00000</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.0</td>\n",
       "      <td>537.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.01676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.619181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105209</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.096133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086065</td>\n",
       "      <td>0.060971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226236</td>\n",
       "      <td>0.074604</td>\n",
       "      <td>0.12849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.943974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyhole         10\"   wool-knit         cpc  side-snap   rest  \\\n",
       "count    537.0  537.000000  537.000000  537.000000      537.0  537.0   \n",
       "mean       0.0    0.011173    0.001862    0.009311        0.0    0.0   \n",
       "std        0.0    0.105209    0.043153    0.096133        0.0    0.0   \n",
       "min        0.0    0.000000    0.000000    0.000000        0.0    0.0   \n",
       "25%        0.0    0.000000    0.000000    0.000000        0.0    0.0   \n",
       "50%        0.0    0.000000    0.000000    0.000000        0.0    0.0   \n",
       "75%        0.0    0.000000    0.000000    0.000000        0.0    0.0   \n",
       "max        0.0    1.000000    1.000000    1.000000        0.0    0.0   \n",
       "\n",
       "           hiking      unisex      v   button-up  ...   this   cord  \\\n",
       "count  537.000000  537.000000  537.0  537.000000  ...  537.0  537.0   \n",
       "mean     0.007449    0.003724    0.0    0.003724  ...    0.0    0.0   \n",
       "std      0.086065    0.060971    0.0    0.060971  ...    0.0    0.0   \n",
       "min      0.000000    0.000000    0.0    0.000000  ...    0.0    0.0   \n",
       "25%      0.000000    0.000000    0.0    0.000000  ...    0.0    0.0   \n",
       "50%      0.000000    0.000000    0.0    0.000000  ...    0.0    0.0   \n",
       "75%      0.000000    0.000000    0.0    0.000000  ...    0.0    0.0   \n",
       "max      1.000000    1.000000    0.0    1.000000  ...    0.0    0.0   \n",
       "\n",
       "            train     tapered   textured    a-d  super-high-rise       nulux  \\\n",
       "count  537.000000  537.000000  537.00000  537.0            537.0  537.000000   \n",
       "mean     0.054004    0.005587    0.01676    0.0              0.0    0.001862   \n",
       "std      0.226236    0.074604    0.12849    0.0              0.0    0.043153   \n",
       "min      0.000000    0.000000    0.00000    0.0              0.0    0.000000   \n",
       "25%      0.000000    0.000000    0.00000    0.0              0.0    0.000000   \n",
       "50%      0.000000    0.000000    0.00000    0.0              0.0    0.000000   \n",
       "75%      0.000000    0.000000    0.00000    0.0              0.0    0.000000   \n",
       "max      1.000000    1.000000    1.00000    0.0              0.0    1.000000   \n",
       "\n",
       "       ruched       Price  \n",
       "count   537.0  537.000000  \n",
       "mean      0.0   96.619181  \n",
       "std       0.0   46.943974  \n",
       "min       0.0   14.000000  \n",
       "25%       0.0   59.000000  \n",
       "50%       0.0   96.000000  \n",
       "75%       0.0  128.000000  \n",
       "max       0.0  369.000000  \n",
       "\n",
       "[8 rows x 708 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df_all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the median of the mens clothing is lower than the median of the womens clothing. This means that the lasso results will probably imply that \"mens\" actually increases prices whereas \"womens\" decreases it. But I wonder if random forest + SHAP values will have to say the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "keyhole             2\n",
      "10\"                 2\n",
      "wool-knit           2\n",
      "cpc                 2\n",
      "side-snap           2\n",
      "                   ..\n",
      "a-d                 2\n",
      "super-high-rise     2\n",
      "nulux               2\n",
      "ruched              2\n",
      "Price              80\n",
      "Length: 708, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.201028350370316\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr()\n",
    "print(correlations.loc['womens', 'Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more strongly negative correlation than Nike's, which was only -0.05, approximately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1037, 707) \n",
      " Y train shape:  (1037, 1) \n",
      " X test shape:  (346, 707) \n",
      " Y test shape:  (346, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "x_train.to_csv(\"x_train.csv\", index=False)\n",
    "x_test.to_csv(\"x_test.csv\", index=False)\n",
    "y_train.to_csv(\"y_train.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n",
    "\n",
    "# save these files as csv so that we use the same data for all different types of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1037, 707) \n",
      " Y train shape:  (1037, 1) \n",
      " X test shape:  (346, 707) \n",
      " Y test shape:  (346, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"x_train.csv\")\n",
    "x_test = pd.read_csv(\"x_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    "\n",
    "print(\"X train shape: \", x_train.shape, \n",
    "      \"\\n Y train shape: \", y_train.shape,\n",
    "       \"\\n X test shape: \", x_test.shape, \n",
    "         \"\\n Y test shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. lasso (alpha = 1)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1479.819080610456\n",
      "Correlation:  0.5185031966221738\n"
     ]
    }
   ],
   "source": [
    "# stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "y_test = y_test.values.flatten()\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(\"Correlation: \", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  675.5647720884425\n",
      "Correlation:  0.8106082450183435\n"
     ]
    }
   ],
   "source": [
    "# that's terrible, let's try a different alpha value. \n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred = lasso.predict(x_test)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "#y_test = y_test.values.flatten()\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(\"Correlation: \", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After playing around with different alpha values it appears that alpha=0.01 gives us the best results with the lowest MSE and highest correlation, going by alpha value to the 0.001. I'm sure there's a better way to find the ideal alpha value but I'll figure that out another day. \n",
    "\n",
    "Now let's see what these coefficients have to say. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Coefficient\n",
      "0            keyhole   -11.611843\n",
      "1                10\"   -14.097912\n",
      "2          wool-knit    58.404503\n",
      "3                cpc     7.954917\n",
      "5               rest    10.976016\n",
      "..               ...          ...\n",
      "699             cord    -0.450938\n",
      "700            train     0.475675\n",
      "702         textured    38.852923\n",
      "704  super-high-rise   -16.657445\n",
      "706           ruched   -16.535639\n",
      "\n",
      "[386 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "coefs = lasso.coef_\n",
    "feature_names = x_train.columns\n",
    "coefs_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "coefs_df = coefs_df[coefs_df['Coefficient'] != 0.0]\n",
    "print(coefs_df)\n",
    "#coefs_df.to_csv(\"coefs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(386, 2)\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So about half the words were found to be influential. that's not great. let's at least see what the \"womens\" coefficient was, along with what the top 10 most influential words were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = coefs_df.sort_values(by='Coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These were the words in the product descriptions behind the biggest price increases, accroding to Lasso: \n",
      "\n",
      "         Feature  Coefficient\n",
      "297  down-filled   151.774012\n",
      "523        parka   134.014472\n",
      "678         puff   133.909356\n",
      "400     overalls    93.478486\n",
      "399   navigation    80.166956\n",
      "565         coat    78.144616\n",
      "281        rebel    77.652953\n",
      "157          25l    77.411228\n",
      "357       duffle    75.071296\n",
      "567      another    74.331474\n"
     ]
    }
   ],
   "source": [
    "print(\"These were the words in the product descriptions behind the biggest price increases, accroding to Lasso: \\n\")\n",
    "print(coefs_df.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These were the words in the product descriptions behind the biggest price DECREASES, accroding to Lasso: \n",
      "\n",
      "             Feature  Coefficient\n",
      "165              hat   -33.870869\n",
      "299             clip   -36.278938\n",
      "413         keychain   -37.413208\n",
      "468         headband   -39.124689\n",
      "355       cap-sleeve   -42.463554\n",
      "506           velvet   -43.304241\n",
      "352            socks   -49.368297\n",
      "256  relaxed-tapered   -50.085643\n",
      "599  classic-tapered   -75.750488\n",
      "543       scrunchies   -76.097227\n"
     ]
    }
   ],
   "source": [
    "print(\"These were the words in the product descriptions behind the biggest price DECREASES, accroding to Lasso: \\n\")\n",
    "\n",
    "print(coefs_df.iloc[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think a general improvement for me would be to separate the adjectives from the nouns. Obviously socks are going to be cheaper than puffers. I think this would provide a better insight into the pricing models. That is for another week. Perhaps I should cut down on my number of datasets then and focus on just 3: Lululemon, Nike, and Gymshark. I think what I do with the data is more important than how many datasets I cover. I am doing a personal project, not a research paper. I should value depth over breadth. \n",
    "\n",
    "### to do: remove nouns and do an ADJECTIVE analysis!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  Coefficient\n",
      "631  womens     -1.13435\n"
     ]
    }
   ],
   "source": [
    "womens_coef = coefs_df[coefs_df['Feature'].str.contains('womens', case=False, na=False)]\n",
    "print(womens_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, pretty low compared to the others (meaning it is not all that influential), and seems to be more favoring women than men. Now let's stop pretending that the pricing model is linear and let's apply some rfr! (Random forest regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/btr2krsx7hx6jcjm7m5dn87m0000gn/T/ipykernel_8042/2580542958.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfr.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.799649497675338\n",
      "Mean squared error:  712.2667368030976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(random_state=16)\n",
    "rfr.fit(x_train, y_train)\n",
    "y_pred = rfr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(\"Pearson correlation coefficient:\", corr)\n",
    "print(\"Mean squared error: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow it actually performed worse than lasso. Perhaps their pricing model is linear? Lol. I'm not sure it's worth it to sit down and look at the SHAP values right now. \n",
    "\n",
    "I think what I really need to do is just get rid of the nouns. They are messing everything up. We need adjectives only. I'm going to have to research how to do that. I think there are already pre-trained models that can easily filter out adjectives from nouns. Worst case, I can always just feed my dataset into chat gpt!!!! That'll filter out all the nouns for me. \n",
    "\n",
    "### Next steps: \n",
    "1. Remove nouns from Nike and Lululemon datasets and see how just plain adjectives influence price. If the adjectives improve the analyses, then yay! Don't bother with SHAP on lululemon for non-adjective dataset. Just rerun the whole thing on all the datasets but without adjectives (gymshark too) and finish up the project. \n",
    "2. If removal of adjectives doesn't improve anything, then run lasso and rfr on Gymshark. If the gymshark ML results show that womens \"decreases\" price, then you know something is wrong, and reach out to Abhi for help. \n",
    "3. However, if the gymshark ML results show that womens \"increases\" prices, then you know all your code is working. Just finish running SHAP values on lululemon price analysis (just to make everything even), and also run everything (lasso and rfr) on Gymshark data too.\n",
    "4. Clean up code and publish. \n",
    "\n",
    "A suggestion I got was to try to reduce the number of features selected during each random forest step. Let's try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/btr2krsx7hx6jcjm7m5dn87m0000gn/T/ipykernel_8042/4110881440.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfr.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.8107210592487684\n",
      "Mean squared error:  685.1503800740472\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(max_features=30, random_state=16)\n",
    "rfr.fit(x_train, y_train)\n",
    "y_pred = rfr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "corr, _ = pearsonr(y_test, y_pred)\n",
    "print(\"Pearson correlation coefficient:\", corr)\n",
    "print(\"Mean squared error: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay yeah it didn't improve it all that much. The highest I could find was .81 correlation which is still not amazing compared to lasso. \n",
    "\n",
    "I think we should try removing the adjectives. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
